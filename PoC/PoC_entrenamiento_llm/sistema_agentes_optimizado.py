#!/usr/bin/env python3
"""
Sistema de Agentes CrewAI OPTIMIZADO para Generaci√≥n de Actividades Educativas
Versi√≥n mejorada con prompts concisos, tools especializadas y templates modulares
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Optional, Any, Mapping
from dataclasses import dataclass
import logging

# Configurar variables de entorno para LiteLLM/CrewAI (configuraci√≥n del proyecto funcional)
os.environ["OLLAMA_BASE_URL"] = "http://192.168.1.10:11434"
os.environ["OLLAMA_HOST"] = "http://192.168.1.10:11434"
os.environ["OLLAMA_API_BASE"] = "http://192.168.1.10:11434"
os.environ["LITELLM_LOG"] = "DEBUG"  # Para debug

# Configuraci√≥n para forzar Ollama sin LiteLLM
os.environ["OPENAI_API_KEY"] = "not-needed"  # Placeholder
os.environ["OPENAI_MODEL_NAME"] = "qwen3:latest"
# Desactivar LiteLLM en CrewAI
os.environ["CREWAI_DISABLE_TELEMETRY"] = "true"

# Configuraci√≥n de timeout
os.environ["HTTPX_TIMEOUT"] = "120"

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("CREWAI_OPTIMIZADO")

# Configurar LiteLLM globalmente antes de los imports de CrewAI
try:
    import litellm
    # Configuraci√≥n espec√≠fica para Ollama
    litellm.set_verbose = True
    # Configurar modelos de Ollama expl√≠citamente
    os.environ["LITELLM_PROVIDER"] = "ollama"
    logger.info("‚úÖ LiteLLM configurado para Ollama")
except ImportError:
    logger.warning("‚ö†Ô∏è LiteLLM no disponible")
    pass

try:
    from crewai import Agent, Task, Crew, Process
    from langchain_community.llms import Ollama
    from langchain.callbacks.manager import CallbackManagerForLLMRun
    from langchain.llms.base import LLM
    from typing import Any, List, Mapping
    logger.info("‚úÖ Dependencias CrewAI cargadas correctamente")
except ImportError as e:
    logger.error(f"‚ùå Error de importaci√≥n: {e}")
    raise ImportError("Instala: pip install crewai crewai-tools langchain-community")

# Importar m√≥dulos de Ollama
from ollama_api_integrator import OllamaAPIEducationGenerator

# Importar nuestros m√≥dulos optimizados
from prompt_manager import PromptTemplateManager
from educational_tools import (
    PerfilAnalyzerTool, ActivityValidatorTool, CurriculumCheckerTool,
    EnvironmentDesignTool, TaskDecomposerTool, StudentTaskMatcherTool
)


class DirectOllamaLLM(LLM):
    """LLM completamente personalizado que bypassa LiteLLM"""
    
    # Declarar campos para Pydantic v2
    ollama_generator: Optional[object] = None
    model_name: str = "qwen3:latest"
    host: str = "192.168.1.10"
    
    def __init__(self, ollama_host: str = "192.168.1.10", ollama_model: str = "qwen3:latest", **kwargs):
        # Separar host y puerto si viene junto
        if ":" in ollama_host:
            host_only = ollama_host.split(":")[0]
        else:
            host_only = ollama_host
            
        # Crear generador de Ollama
        ollama_gen = OllamaAPIEducationGenerator(
            host=host_only, 
            model_name=ollama_model
        )
        
        # Inicializar con los campos requeridos
        super().__init__(
            ollama_generator=ollama_gen,
            model_name=ollama_model,
            host=host_only,
            **kwargs
        )
    
    @property
    def _llm_type(self) -> str:
        return "direct_ollama"
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        """Llamada principal al LLM - usa nuestro OllamaAPIEducationGenerator"""
        try:
            result = self.ollama_generator.generar_texto(
                prompt=prompt,
                max_tokens=kwargs.get('max_tokens', 800),
                temperature=kwargs.get('temperature', 0.7)
            )
            return result
        except Exception as e:
            logger.error(f"Error en DirectOllamaLLM: {e}")
            return f"Error generando respuesta con Ollama local: {str(e)}"
    
    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        """Par√°metros que identifican este LLM"""
        return {
            "llm_type": "direct_ollama",
            "model_name": self.model_name,
            "host": self.host
        }


@dataclass
class ActividadEducativa:
    """Estructura de datos para una actividad educativa"""
    id: str
    titulo: str
    materia: str
    tema: str
    contenido: str
    estudiantes_objetivo: List[str]
    tipo: str
    adaptaciones: List[str]
    metadatos: Dict
    timestamp: str


class SistemaAgentesOptimizado:
    """Sistema principal de agentes optimizado para generaci√≥n de actividades educativas"""
    
    def __init__(self, 
                 ollama_host: str = "192.168.1.10", 
                 perfiles_model: str = "qwen3:latest",
                 disenador_model: str = "qwen3:latest", 
                 ambiente_model: str = "qwen2:latest",
                 evaluador_model: str = "mistral:latest",
                 perfiles_path: str = "perfiles_4_primaria.json"):
        """
        Inicializa el sistema de agentes optimizado
        """
        self.ollama_host = ollama_host
        self.perfiles_model = perfiles_model
        self.disenador_model = disenador_model
        self.ambiente_model = ambiente_model
        self.evaluador_model = evaluador_model
        self.perfiles_path = perfiles_path
        
        # Cargar perfiles y crear gestores
        self.perfiles_data = self._cargar_perfiles(perfiles_path)
        try:
            self.prompt_manager = PromptTemplateManager(self.perfiles_data)
        except Exception as e:
            logger.warning(f"Error creando PromptTemplateManager: {e}")
            # Usar datos por defecto si fallan los perfiles
            perfiles_default = self._crear_perfiles_default()
            self.prompt_manager = PromptTemplateManager(perfiles_default)
        
        # Crear LLMs espec√≠ficos para cada agente
        logger.info("üîß Configurando LLMs optimizados...")
        self._crear_llms()
        
        # Crear tools especializadas
        logger.info("üõ†Ô∏è Inicializando tools especializadas...")
        self._crear_tools()
        
        # Crear agentes optimizados
        logger.info("ü§ñ Creando agentes optimizados...")
        self._crear_agentes_optimizados()
        
        logger.info(f"‚úÖ Sistema optimizado inicializado con modelos:")
        logger.info(f"   üìä Perfiles: {self.perfiles_model}")
        logger.info(f"   üé® Dise√±ador: {self.disenador_model}")
        logger.info(f"   ü§ù Ambiente: {self.ambiente_model}")  
        logger.info(f"   ‚úÖ Evaluador: {self.evaluador_model}")
    
    def _cargar_perfiles(self, perfiles_path: str) -> List[Dict]:
        """Cargar perfiles de estudiantes desde archivo JSON"""
        try:
            # Crear ruta absoluta si es relativa
            if not os.path.isabs(perfiles_path):
                script_dir = os.path.dirname(os.path.abspath(__file__))
                perfiles_path = os.path.join(script_dir, perfiles_path)
            
            with open(perfiles_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('estudiantes', [])
        except Exception as e:
            logger.error(f"Error cargando perfiles: {e}")
            return self._crear_perfiles_default()
    
    def _crear_perfiles_default(self) -> List[Dict]:
        """Crea perfiles por defecto si no se pueden cargar"""
        return [
            {"id": "001", "nombre": "ALEX M.", "temperamento": "reflexivo", "canal_preferido": "visual", "diagnostico_formal": "ninguno", "ci_base": 102},
            {"id": "002", "nombre": "MAR√çA L.", "temperamento": "reflexivo", "canal_preferido": "auditivo", "diagnostico_formal": "ninguno"},
            {"id": "003", "nombre": "ELENA R.", "temperamento": "reflexivo", "canal_preferido": "visual", "diagnostico_formal": "TEA_nivel_1", "ci_base": 118},
            {"id": "004", "nombre": "LUIS T.", "temperamento": "impulsivo", "canal_preferido": "kinest√©sico", "diagnostico_formal": "TDAH_combinado", "ci_base": 102},
            {"id": "005", "nombre": "ANA V.", "temperamento": "reflexivo", "canal_preferido": "auditivo", "diagnostico_formal": "altas_capacidades", "ci_base": 141},
            {"id": "006", "nombre": "SARA M.", "temperamento": "equilibrado", "canal_preferido": "auditivo", "diagnostico_formal": "ninguno", "ci_base": 115},
            {"id": "007", "nombre": "EMMA K.", "temperamento": "reflexivo", "canal_preferido": "visual", "diagnostico_formal": "ninguno", "ci_base": 132},
            {"id": "008", "nombre": "HUGO P.", "temperamento": "equilibrado", "canal_preferido": "visual", "diagnostico_formal": "ninguno", "ci_base": 114}
        ]
    
    def _crear_llms(self):
        """Crea LLMs espec√≠ficos para cada agente con configuraci√≥n LiteLLM"""
        try:
            # Configurar LiteLLM correctamente para Ollama (soluci√≥n del proyecto anterior)
            import litellm
            
            logger.info(f"üîß Configurando LiteLLM para Ollama local...")
            
            # Mapear todos los modelos para LiteLLM
            modelos_unicos = set([self.ambiente_model, self.disenador_model, self.perfiles_model, self.evaluador_model])
            for modelo in modelos_unicos:
                litellm.model_cost[f"ollama/{modelo}"] = {
                    "input_cost_per_token": 0,
                    "output_cost_per_token": 0,
                    "max_tokens": 4096
                }
            
            # Configurar variables espec√≠ficas para LiteLLM + Ollama
            os.environ["OLLAMA_API_BASE"] = f"http://{self.ollama_host}:11434"
            os.environ["OLLAMA_BASE_URL"] = f"http://{self.ollama_host}:11434"
            
            # Crear LLMs espec√≠ficos para cada agente (sin prefijo para conexi√≥n directa)
            self.perfiles_llm = Ollama(
                model=self.perfiles_model,
                base_url=f"http://{self.ollama_host}:11434"
            )
            
            self.disenador_llm = Ollama(
                model=self.disenador_model,
                base_url=f"http://{self.ollama_host}:11434"
            )
            
            self.ambiente_llm = Ollama(
                model=self.ambiente_model,
                base_url=f"http://{self.ollama_host}:11434"
            )
            
            self.evaluador_llm = Ollama(
                model=self.evaluador_model,
                base_url=f"http://{self.ollama_host}:11434"
            )
            
            # Verificar conexi√≥n
            try:
                test_response = self.perfiles_llm.invoke("Test de conexi√≥n")
                logger.info("‚úÖ LLMs configurados exitosamente")
            except Exception as test_error:
                logger.error(f"‚ùå Fallo en test de conexi√≥n: {test_error}")
                raise ConnectionError("No se pudo conectar con Ollama. Verifica que el servicio est√© corriendo.")
                
        except Exception as e:
            logger.error(f"‚ùå Error configurando LLMs: {e}")
            raise
    
    def _crear_tools(self):
        """Crea tools especializadas para cada agente"""
        try:
            # Tools originales
            self.perfil_tool = PerfilAnalyzerTool(self.perfiles_data)
            self.validator_tool = ActivityValidatorTool()
            self.curriculum_tool = CurriculumCheckerTool()
            
            # Nuevas tools para el flujo redise√±ado
            self.environment_tool = EnvironmentDesignTool()
            self.decomposer_tool = TaskDecomposerTool()
            self.matcher_tool = StudentTaskMatcherTool()
            
            logger.info("‚úÖ Tools especializadas creadas (incluyendo nuevas tools de flujo)")
        except Exception as e:
            logger.error(f"Error creando tools: {e}")
            # Crear tools vac√≠as como fallback
            self.perfil_tool = PerfilAnalyzerTool([])
            self.validator_tool = ActivityValidatorTool()
            self.curriculum_tool = CurriculumCheckerTool()
            logger.info("‚ö†Ô∏è Tools creadas con datos por defecto")
    
    def _crear_agentes_optimizados(self):
        """Crea agentes con nuevo flujo: Ambiente ‚Üí Dise√±o ‚Üí Desglose ‚Üí Asignaci√≥n"""
        
        # AGENTE 1: DISE√ëADOR DE AMBIENTE DE APRENDIZAJE (NUEVO)
        self.agente_ambiente = Agent(
            role="Dise√±ador de Ambiente de Aprendizaje",
            goal="Establecer el tono y caracter√≠sticas generales √≥ptimas para la actividad educativa",
            backstory="Especialista en ambientes de aprendizaje. Analizas las caracter√≠sticas del grupo y defines si la actividad debe ser l√∫dica, investigativa, creativa o de concentraci√≥n. IMPORTANTE: Usa dise√±ar_ambiente UNA SOLA VEZ. Respondes siempre en espa√±ol.",
            tools=[self.environment_tool],  # Tool para dise√±ar ambiente
            llm=self.ambiente_llm,
            verbose=True,
            allow_delegation=False
        )
        
        # AGENTE 2: DISE√ëADOR DE ACTIVIDADES ESTRUCTURADAS (MODIFICADO)
        self.agente_disenador = Agent(
            role="Dise√±ador de Actividades Estructuradas",
            goal="Crear actividades espec√≠ficas basadas en la base ambiental establecida",
            backstory="Docente experto en dise√±o curricular. Tomas la base ambiental y creas actividades estructuradas espec√≠ficas por materia. Usas verificar_curriculum para asegurar objetivos. Respondes siempre en espa√±ol.",
            tools=[self.curriculum_tool],  # Tool para verificar objetivos curriculares
            llm=self.disenador_llm,
            verbose=True,
            allow_delegation=False
        )
        
        # AGENTE 3: DESGLOSADOR DE TAREAS (NUEVO)
        self.agente_desglosador = Agent(
            role="Desglosador de Tareas Espec√≠ficas",
            goal="Descomponer actividades en tareas micro-espec√≠ficas con requerimientos detallados",
            backstory="Especialista en an√°lisis de tareas educativas. Descompones actividades complejas en tareas individuales espec√≠ficas, analizando habilidades requeridas y dependencias. IMPORTANTE: Usa descomponer_tareas UNA SOLA VEZ. Respondes siempre en espa√±ol.",
            tools=[self.decomposer_tool],  # Tool para descomponer tareas
            llm=self.perfiles_llm,  # Reutilizar modelo de perfiles
            verbose=True,
            allow_delegation=False
        )
        
        # AGENTE 4: ASIGNADOR DE ROLES PERSONALIZADO (NUEVO)
        self.agente_asignador = Agent(
            role="Asignador de Roles Personalizado",
            goal="Emparejar tareas espec√≠ficas con estudiantes seg√∫n su Zona de Desarrollo Pr√≥ximo",
            backstory="Psicopedagogo especializado en ZDP y personalizaci√≥n. Asignas tareas espec√≠ficas a estudiantes considerando sus fortalezas, desaf√≠os y zona de desarrollo pr√≥ximo. IMPORTANTE: Usa asignar_tareas_estudiantes UNA SOLA VEZ. Respondes siempre en espa√±ol.",
            tools=[self.matcher_tool],  # Tool para emparejar estudiantes-tareas
            llm=self.evaluador_llm,  # Reutilizar modelo evaluador
            verbose=True,
            allow_delegation=False
        )
        
        logger.info("‚úÖ Agentes reorganizados creados con nuevo flujo pedag√≥gico")
    
    def generar_actividad_colaborativa(self, materia: str, tema: str = None) -> ActividadEducativa:
        """Genera una actividad colaborativa usando el sistema optimizado"""
        
        logger.info(f"üë• Generando actividad colaborativa optimizada para {materia}")
        
        try:
            # Crear tareas con nuevo flujo
            tarea_ambiente = Task(
                description=self.prompt_manager.generar_prompt(materia, "ambiente"),
                agent=self.agente_ambiente,
                expected_output="Base ambiental definida con justificaci√≥n pedag√≥gica"
            )
            
            tarea_diseno = Task(
                description=self.prompt_manager.generar_prompt(materia, "diseno", tema),
                agent=self.agente_disenador,
                context=[tarea_ambiente],
                expected_output="Actividad estructurada espec√≠fica"
            )
            
            tarea_desglose = Task(
                description=self.prompt_manager.generar_prompt(materia, "desglose"),
                agent=self.agente_desglosador,
                context=[tarea_diseno],
                expected_output="Desglose completo en tareas micro-espec√≠ficas"
            )
            
            tarea_asignacion = Task(
                description=self.prompt_manager.generar_prompt(materia, "asignacion"),
                agent=self.agente_asignador,
                context=[tarea_desglose],
                expected_output="Asignaci√≥n optimizada de tareas por estudiante"
            )

            # Crear y ejecutar crew
            crew = Crew(
                agents=[self.agente_ambiente, self.agente_disenador, self.agente_desglosador, self.agente_asignador],
                tasks=[tarea_ambiente, tarea_diseno, tarea_desglose, tarea_asignacion],
                process=Process.sequential,
                verbose=True
            )
            
            logger.info("üöÄ Ejecutando workflow optimizado...")
            resultado = crew.kickoff()
            
            # Procesar resultados
            contenido_completo = self._procesar_resultados(resultado)
            
            return ActividadEducativa(
                id=f"flujo_pedagogico_{materia.lower()}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                titulo=f"Actividad Colaborativa - {materia}",
                materia=materia,
                tema=tema or "tema general",
                contenido=contenido_completo,
                estudiantes_objetivo=["001", "002", "003", "004", "005", "006", "007", "008"],
                tipo="colaborativa_flujo_pedagogico",
                adaptaciones=["ambiente_personalizado", "tareas_especificas", "asignacion_zdp"],
                metadatos={
                    "sistema": "flujo_pedagogico_reorganizado",
                    "timestamp": datetime.now().isoformat()
                },
                timestamp=datetime.now().isoformat()
            )
        
        except Exception as e:
            logger.error(f"Error generando actividad: {e}")
            # Retornar actividad b√°sica
            return ActividadEducativa(
                id=f"error_{materia.lower()}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                titulo=f"Actividad B√°sica - {materia}",
                materia=materia,
                tema=tema or "tema general",
                contenido=f"Error generando actividad: {e}",
                estudiantes_objetivo=[],
                tipo="error_fallback",
                adaptaciones=[],
                metadatos={"error": str(e)},
                timestamp=datetime.now().isoformat()
            )
    
    def _procesar_resultados(self, resultado) -> str:
        """Procesa y estructura los resultados del crew"""
        contenido = ""
        
        try:
            if hasattr(resultado, 'tasks_output') and resultado.tasks_output:
                contenido += "=== DISE√ëO DE AMBIENTE DE APRENDIZAJE ===\n"
                contenido += str(resultado.tasks_output[0]) + "\n\n"
                
                contenido += "=== DISE√ëO DE ACTIVIDAD ESTRUCTURADA ===\n"
                contenido += str(resultado.tasks_output[1]) + "\n\n"
                
                contenido += "=== DESGLOSE EN TAREAS ESPEC√çFICAS ===\n"
                contenido += str(resultado.tasks_output[2]) + "\n\n"
                
                contenido += "=== ASIGNACI√ìN PERSONALIZADA POR ZDP ===\n"
                contenido += str(resultado.tasks_output[3]) + "\n\n"
            else:
                contenido = str(resultado)
        except Exception as e:
            logger.warning(f"Error procesando resultados: {e}")
            contenido = str(resultado)
        
        return contenido
    
    def guardar_actividad(self, actividad: ActividadEducativa, output_dir: str = "actividades_optimizadas") -> str:
        """Guarda una actividad optimizada en un archivo"""
        
        script_dir = os.path.dirname(os.path.abspath(__file__))
        full_output_dir = os.path.join(script_dir, output_dir)
        os.makedirs(full_output_dir, exist_ok=True)
        
        filename = f"{actividad.id}.txt"
        filepath = os.path.join(full_output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write(f"ACTIVIDAD GENERADA CON SISTEMA OPTIMIZADO CrewAI + Ollama\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"ID: {actividad.id}\n")
            f.write(f"T√≠tulo: {actividad.titulo}\n")
            f.write(f"Materia: {actividad.materia}\n")
            f.write(f"Tema: {actividad.tema}\n")
            f.write(f"Tipo: {actividad.tipo}\n")
            f.write(f"Estudiantes objetivo: {', '.join(actividad.estudiantes_objetivo)}\n")
            f.write(f"Timestamp: {actividad.timestamp}\n")
            f.write("\n" + "-" * 50 + "\n")
            f.write("CONTENIDO DE LA ACTIVIDAD:\n")
            f.write("-" * 50 + "\n\n")
            f.write(actividad.contenido)
            f.write("\n\n" + "=" * 80 + "\n")
            f.write("METADATOS DEL SISTEMA OPTIMIZADO:\n")
            f.write(json.dumps(actividad.metadatos, indent=2, ensure_ascii=False))
            f.write("\n")
        
        logger.info(f"üíæ Actividad optimizada guardada en: {filepath}")
        return filepath
    
    def ejecutar_workflow_completo(self, materia: str, tema: str = None) -> Dict:
        """Ejecuta workflow completo optimizado"""
        
        logger.info(f"üöÄ Iniciando workflow optimizado para {materia}")
        start_time = datetime.now()
        
        resultados = {
            "sistema": "optimizado",
            "materia": materia,
            "tema": tema,
            "timestamp": start_time.isoformat(),
            "actividades_generadas": [],
            "archivos_creados": [],
            "metricas": {}
        }
        
        try:
            # Generar actividad colaborativa optimizada
            logger.info("ü§ù Generando actividad colaborativa optimizada...")
            actividad = self.generar_actividad_colaborativa(materia, tema)
            archivo = self.guardar_actividad(actividad)
            
            end_time = datetime.now()
            duracion = (end_time - start_time).total_seconds()
            
            resultados["actividades_generadas"].append({
                "tipo": "colaborativa_optimizada",
                "id": actividad.id,
                "archivo": archivo
            })
            resultados["archivos_creados"].append(archivo)
            resultados["metricas"] = {
                "duracion_segundos": duracion,
                "tokens_estimados": len(actividad.contenido) // 4,  # Estimaci√≥n rough
                "modelos_utilizados": 4,
                "tools_aplicadas": 3
            }
            
            logger.info(f"‚úÖ Workflow optimizado completado en {duracion:.1f}s")
            
        except Exception as e:
            logger.error(f"‚ùå Error en workflow optimizado: {e}")
            resultados["error"] = str(e)
        
        return resultados
    
    def comparar_con_sistema_original(self, materia: str, tema: str = None) -> Dict:
        """Compara rendimiento con sistema original (para testing)"""
        
        logger.info(f"üìä Ejecutando comparaci√≥n de sistemas para {materia}")
        
        # Ejecutar sistema optimizado
        resultado_optimizado = self.ejecutar_workflow_completo(materia, tema)
        
        comparacion = {
            "sistema_optimizado": resultado_optimizado,
            "mejoras_implementadas": [
                "Prompts reducidos de 400+ l√≠neas a 50-80 l√≠neas",
                "Tools especializadas integradas (3 tools)",
                "Templates modulares reutilizables",
                "Validaci√≥n autom√°tica de calidad",
                "Verificaci√≥n curricular integrada"
            ],
            "ventajas_esperadas": [
                "Menor tiempo de ejecuci√≥n",
                "Respuestas m√°s consistentes",
                "Menor uso de tokens",
                "Mejor calidad pedag√≥gica",
                "Mayor mantenibilidad"
            ]
        }
        
        return comparacion


def main():
    """Funci√≥n principal de demostraci√≥n del sistema optimizado"""
    
    print("="*70)
    print("üöÄ SISTEMA DE AGENTES CREWAI OPTIMIZADO PARA EDUCACI√ìN")
    print("="*70)
    
    try:
        # Configuraci√≥n optimizada
        OLLAMA_HOST = "192.168.1.10"
        PERFILES_MODEL = "qwen3:latest"
        DISENADOR_MODEL = "qwen3:latest"
        AMBIENTE_MODEL = "qwen2:latest"
        EVALUADOR_MODEL = "mistral:latest"
        PERFILES_PATH = "perfiles_4_primaria.json"
        
        print(f"\nüîß Inicializando sistema optimizado:")
        print(f"   Host Ollama: {OLLAMA_HOST}")
        print(f"   Modelos especializados por agente:")
        print(f"     üìä Perfiles: {PERFILES_MODEL}")
        print(f"     üé® Dise√±ador: {DISENADOR_MODEL}")
        print(f"     ü§ù Ambiente: {AMBIENTE_MODEL}")
        print(f"     ‚úÖ Evaluador: {EVALUADOR_MODEL}")
        
        sistema = SistemaAgentesOptimizado(
            ollama_host=OLLAMA_HOST,
            perfiles_model=PERFILES_MODEL,
            disenador_model=DISENADOR_MODEL,
            ambiente_model=AMBIENTE_MODEL,
            evaluador_model=EVALUADOR_MODEL,
            perfiles_path=PERFILES_PATH
        )
        
        print("\n‚úÖ Sistema optimizado inicializado correctamente!")
        
        # Men√∫ optimizado
        while True:
            print("\n" + "="*60)
            print("üéØ SISTEMA OPTIMIZADO DE ACTIVIDADES COLABORATIVAS")
            print("1. üöÄ Generar actividad optimizada")
            print("2. üìä Ejecutar workflow completo con m√©tricas")
            print("3. üî¨ Comparar con sistema original")
            print("4. ‚ùå Salir")
            
            opcion = input("\nüëâ Selecciona una opci√≥n (1-4): ").strip()
            
            if opcion == "1":
                print("\nüöÄ GENERACI√ìN OPTIMIZADA")
                materia_input = input("üìö Materia (matematicas/lengua/ciencias): ").strip().lower()
                # Normalizar entrada
                if materia_input in ["mates", "mate"]:
                    materia = "matematicas"
                elif materia_input in ["lengua", "lenguaje"]:
                    materia = "lengua"
                elif materia_input in ["ciencias", "ciencia"]:
                    materia = "ciencias"
                else:
                    materia = materia_input
                tema = input("üìù Tema espec√≠fico (opcional): ").strip() or None
                
                start_time = datetime.now()
                actividad = sistema.generar_actividad_colaborativa(materia, tema)
                archivo = sistema.guardar_actividad(actividad)
                end_time = datetime.now()
                
                duracion = (end_time - start_time).total_seconds()
                
                print(f"\n‚úÖ Actividad optimizada generada en {duracion:.1f}s:")
                print(f"   üìÑ ID: {actividad.id}")
                print(f"   üìÅ Archivo: {archivo}")
                print(f"   üéØ Sistema: Optimizado con tools integradas")
            
            elif opcion == "2":
                print("\nüìä WORKFLOW COMPLETO CON M√âTRICAS")
                materia_input = input("üìö Materia (matematicas/lengua/ciencias): ").strip().lower()
                # Normalizar entrada
                if materia_input in ["mates", "mate"]:
                    materia = "matematicas"
                elif materia_input in ["lengua", "lenguaje"]:
                    materia = "lengua"
                elif materia_input in ["ciencias", "ciencia"]:
                    materia = "ciencias"
                else:
                    materia = materia_input
                tema = input("üìù Tema espec√≠fico (opcional): ").strip() or None
                
                resultados = sistema.ejecutar_workflow_completo(materia, tema)
                
                if "error" not in resultados:
                    print(f"\nüéâ ¬°Workflow optimizado completado!")
                    print(f"   ‚è±Ô∏è  Duraci√≥n: {resultados['metricas']['duracion_segundos']:.1f}s")
                    print(f"   üî¢ Tokens estimados: {resultados['metricas']['tokens_estimados']}")
                    print(f"   ü§ñ Modelos utilizados: {resultados['metricas']['modelos_utilizados']}")
                    print(f"   üõ†Ô∏è  Tools aplicadas: {resultados['metricas']['tools_aplicadas']}")
                    print(f"   üìÅ Archivo: {resultados['archivos_creados'][0]}")
                else:
                    print(f"\n‚ùå Error: {resultados['error']}")
            
            elif opcion == "3":
                print("\nüî¨ COMPARACI√ìN DE SISTEMAS")
                materia_input = input("üìö Materia para comparar: ").strip().lower()
                # Normalizar entrada
                if materia_input in ["mates", "mate"]:
                    materia = "matematicas"
                elif materia_input in ["lengua", "lenguaje"]:
                    materia = "lengua"
                elif materia_input in ["ciencias", "ciencia"]:
                    materia = "ciencias"
                else:
                    materia = materia_input
                tema = input("üìù Tema (opcional): ").strip() or None
                
                comparacion = sistema.comparar_con_sistema_original(materia, tema)
                
                print(f"\nüìà COMPARACI√ìN COMPLETADA:")
                print(f"   üöÄ Sistema optimizado ejecutado exitosamente")
                print(f"   ‚è±Ô∏è  Duraci√≥n: {comparacion['sistema_optimizado']['metricas']['duracion_segundos']:.1f}s")
                
                print(f"\nüîß MEJORAS IMPLEMENTADAS:")
                for mejora in comparacion['mejoras_implementadas']:
                    print(f"   ‚úÖ {mejora}")
            
            elif opcion == "4":
                print("\nüëã ¬°Hasta luego!")
                break
            
            else:
                print("\n‚ùå Opci√≥n no v√°lida. Selecciona 1-4.")
    
    except Exception as e:
        print(f"\n‚ùå Error inicializando sistema optimizado: {e}")
        print("\nüí° Verifica que:")
        print("   1. Ollama est√© ejecut√°ndose")
        print("   2. Los modelos especificados est√©n disponibles")
        print("   3. El archivo de perfiles exista")
        print("   4. Los m√≥dulos prompt_manager.py y educational_tools.py est√©n disponibles")


if __name__ == "__main__":
    main()